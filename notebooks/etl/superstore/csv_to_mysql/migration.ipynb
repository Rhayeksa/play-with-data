{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Migration CSV To Mysql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/24 17:45:30 WARN Utils: Your hostname, rhayeksa-Infinix-INBook-X1 resolves to a loopback address: 127.0.1.1; using 192.168.0.108 instead (on interface wlo1)\n",
      "24/12/24 17:45:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/12/24 17:45:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib.parse\n",
    "\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Environment Variables\n",
    "load_dotenv(dotenv_path=\"../../../../.env\")\n",
    "MYSQL_DB = os.getenv(\"MYSQL_DB\")\n",
    "MYSQL_DB = os.getenv(\"MYSQL_DB\")\n",
    "MYSQL_DB_USERNAME = os.getenv(\"MYSQL_DB_USERNAME\")\n",
    "MYSQL_DB_PASSWORD = os.getenv(\"MYSQL_DB_PASSWORD\")\n",
    "MYSQL_DB_HOST = os.getenv(\"MYSQL_DB_HOST\")\n",
    "MYSQL_DB_PORT = os.getenv(\"MYSQL_DB_PORT\")\n",
    "\n",
    "# Spark Session\n",
    "spark = SparkSession.Builder() \\\n",
    "    .appName(\"Play With Data\") \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .config(\"spark.jars\", \"../../../../library/mysql-connector-j-8.1.0.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Dataframe\n",
    "df_csv_superstore = spark.read.csv(\n",
    "    path=\"../../../../data/raw/sample_superstore.csv\",\n",
    "    header=True,\n",
    "    sep=\",\",\n",
    "    escape='\"'\n",
    ")\n",
    "df_csv_superstore = df_csv_superstore.where(\n",
    "    df_csv_superstore[\"Product ID\"] != \"TEC-AC-10004659\"\n",
    ")\n",
    "df_csv_superstore.createOrReplaceTempView(\"df_csv_superstore\")\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "\n",
    "# DB Connection\n",
    "URI = f\"mysql+pymysql://{MYSQL_DB_USERNAME}:{urllib.parse.quote_plus(\n",
    "    MYSQL_DB_PASSWORD)}@{MYSQL_DB_HOST}:{MYSQL_DB_PORT}/{MYSQL_DB}\"\n",
    "engine = create_engine(url=URI, pool_pre_ping=True)\n",
    "session = sessionmaker(bind=engine)\n",
    "session = session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "TBL_CUST_ADDR = \"tbl_customer_addr\"\n",
    "TBL_SAL_ORD = \"tbl_sales_order\"\n",
    "FK_CUST_ADDR_CUST = \"fk_cust_addr_cust\"\n",
    "FK_SAL_ODR_CUST = \"fk_sal_ord_cust\"\n",
    "try:\n",
    "    qry = session.execute(text(\n",
    "        f\"\"\"\n",
    "        SELECT TABLE_NAME, INDEX_NAME\n",
    "        FROM INFORMATION_SCHEMA.STATISTICS\n",
    "        WHERE index_schema = '{MYSQL_DB}'\n",
    "        AND TABLE_NAME IN('{TBL_CUST_ADDR}', '{TBL_SAL_ORD}')\n",
    "        AND INDEX_NAME IN('{FK_CUST_ADDR_CUST}', '{FK_SAL_ODR_CUST}')\n",
    "        \"\"\"\n",
    "    )).mappings().fetchall()\n",
    "    if len(qry) > 0:\n",
    "        for i in qry:\n",
    "            session.execute(text(\n",
    "                f\"\"\"\n",
    "                ALTER TABLE {MYSQL_DB}.{i[\"TABLE_NAME\"]}\n",
    "                    DROP FOREIGN KEY {i[\"INDEX_NAME\"]}\n",
    "                    , DROP INDEX {i[\"INDEX_NAME\"]}\n",
    "                \"\"\"\n",
    "            ))\n",
    "    session.execute(text(f\"DROP TABLE IF EXISTS {MYSQL_DB}.tbl_customer\"))\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {MYSQL_DB}.tbl_customer(\n",
    "          customer_id VARCHAR(25) NOT NULL\n",
    "          , name VARCHAR(45) NOT NULL\n",
    "          , segment VARCHAR(15) NOT NULL\n",
    "          , PRIMARY KEY (customer_id)\n",
    "        )\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    qry = spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "          `Customer ID` AS customer_id\n",
    "          , `Customer Name` AS customer_name\n",
    "          , segment\n",
    "        FROM df_csv_superstore\n",
    "        GROUP BY `Customer ID`, `Customer Name`, segment\n",
    "        \"\"\"\n",
    "    )\n",
    "    qry = np.array(qry.toJSON().map(json.loads).collect())\n",
    "\n",
    "    val = str()\n",
    "    for i in range(len(qry)):\n",
    "        customer_id = str(qry[i]['customer_id']).replace(\"'\", \"\\\\'\")\n",
    "        customer_name = str(qry[i]['customer_name']).replace(\"'\", \"\\\\'\")\n",
    "        segment = str(qry[i]['segment']).replace(\"'\", \"\\\\'\")\n",
    "        if i == 0:\n",
    "            val += f\"('{customer_id}', '{customer_name}', '{segment}')\"\n",
    "        else:\n",
    "            val += f\", ('{customer_id}', '{customer_name}', '{segment}')\"\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        INSERT INTO {MYSQL_DB}.tbl_customer(customer_id, name, segment)\n",
    "        VALUES {val}\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "    print(\"Successfully migrated\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError msg : {e}\\n\")\n",
    "    session.rollback()\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.execute(text(f\"DROP TABLE IF EXISTS {MYSQL_DB}.tbl_customer_addr\"))\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {MYSQL_DB}.tbl_customer_addr(\n",
    "            customer_addr_id VARCHAR(25) NOT NULL\n",
    "            , customer_id VARCHAR(25) NOT NULL\n",
    "            , country VARCHAR(15) NOT NULL\n",
    "            , city VARCHAR(25) NOT NULL\n",
    "            , state VARCHAR(25) NOT NULL\n",
    "            , postal_code INT NOT NULL\n",
    "            , region VARCHAR(10) NOT NULL\n",
    "            , PRIMARY KEY (customer_addr_id)\n",
    "        )\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    qry = spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "            `Customer ID` customer_id\n",
    "            , country\n",
    "            , city\n",
    "            , state\n",
    "            , `postal code` postal_code\n",
    "            , region\n",
    "        FROM df_csv_superstore\n",
    "        GROUP BY `customer id`, country, city, state, `postal code`, region\n",
    "        \"\"\"\n",
    "    )\n",
    "    qry = np.array(qry.toJSON().map(json.loads).collect())\n",
    "\n",
    "    val = str()\n",
    "    for i in range(len(qry)):\n",
    "        cust_addr_id = f\"CUST-ADDR-{i+1}\"\n",
    "        customer_id = str(qry[i]['customer_id']).replace(\"'\", \"\\\\'\")\n",
    "        country = str(qry[i]['country']).replace(\"'\", \"\\\\'\")\n",
    "        city = str(qry[i]['city']).replace(\"'\", \"\\\\'\")\n",
    "        state = str(qry[i]['state']).replace(\"'\", \"\\\\'\")\n",
    "        postal_code = str(qry[i]['postal_code']).replace(\"'\", \"\\\\'\")\n",
    "        region = str(qry[i]['region']).replace(\"'\", \"\\\\'\")\n",
    "        if i == 0:\n",
    "            val += f\"\"\"(\n",
    "                        '{cust_addr_id}', '{customer_id}', '{country}', '{city}', '{state}', '{postal_code}', '{region}'\n",
    "                    )\"\"\"\n",
    "        else:\n",
    "            val += f\"\"\", (\n",
    "                        '{cust_addr_id}', '{customer_id}', '{country}', '{city}', '{state}', '{postal_code}', '{region}'\n",
    "                    )\"\"\"\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        INSERT INTO {MYSQL_DB}.tbl_customer_addr(customer_addr_id, customer_id, country, city, state, postal_code, region)\n",
    "        VALUES {val}\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "    print(\"Successfully migrated\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError msg : {e}\\n\")\n",
    "    session.rollback()\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated\n"
     ]
    }
   ],
   "source": [
    "TBL_PROD_PRC = \"tbl_product_price\"\n",
    "TBL_SAL_ORD_DET = \"tbl_sales_order_detail\"\n",
    "FK_PROD_PRC_PROD = \"fk_prod_prc_prod\"\n",
    "FK_SAL_ORD_DET_PROD = \"fk_sal_ord_det_prod\"\n",
    "try:\n",
    "    qry = session.execute(text(\n",
    "        f\"\"\"\n",
    "        SELECT TABLE_NAME, INDEX_NAME\n",
    "        FROM INFORMATION_SCHEMA.STATISTICS\n",
    "        WHERE index_schema = '{MYSQL_DB}'\n",
    "        AND TABLE_NAME IN('{TBL_PROD_PRC}', '{TBL_SAL_ORD_DET}')\n",
    "        AND INDEX_NAME IN('{FK_PROD_PRC_PROD}', '{FK_SAL_ORD_DET_PROD}')\n",
    "        \"\"\"\n",
    "    )).mappings().fetchall()\n",
    "    if len(qry) > 0:\n",
    "        for i in qry:\n",
    "            session.execute(text(\n",
    "                f\"\"\"\n",
    "                ALTER TABLE {MYSQL_DB}.{i[\"TABLE_NAME\"]}\n",
    "                    DROP FOREIGN KEY {i[\"INDEX_NAME\"]}\n",
    "                    , DROP INDEX {i[\"INDEX_NAME\"]}\n",
    "                \"\"\"\n",
    "            ))\n",
    "    session.execute(text(f\"DROP TABLE IF EXISTS {MYSQL_DB}.tbl_product\"))\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {MYSQL_DB}.tbl_product(\n",
    "          product_id VARCHAR(20) NOT NULL\n",
    "          , name VARCHAR(225) NOT NULL\n",
    "          , category VARCHAR(15) NOT NULL\n",
    "          , sub_category VARCHAR(15) NOT NULL\n",
    "          , PRIMARY KEY (product_id)\n",
    "        )\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    qry = spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "            `product id` product_id\n",
    "            , `product name` product_name\n",
    "            , category\n",
    "            , `sub-category` sub_category\n",
    "        FROM df_csv_superstore\n",
    "        GROUP BY `product id`, `product name`, category, `sub-category`\n",
    "        \"\"\"\n",
    "    )\n",
    "    qry = np.array(qry.toJSON().map(json.loads).collect())\n",
    "\n",
    "    for i in qry:\n",
    "        qry_prod_id = session.execute(text(\n",
    "            f\"\"\"\n",
    "            SELECT product_id FROM {MYSQL_DB}.tbl_product WHERE product_id = :product_id\n",
    "            \"\"\"\n",
    "        ), {\"product_id\": i[\"product_id\"]}).mappings().fetchone()\n",
    "        qry_prod_id = f\"{i[\"product_id\"]}D\" if qry_prod_id else i[\"product_id\"]\n",
    "\n",
    "        session.execute(text(\n",
    "            f\"\"\"\n",
    "            INSERT INTO {MYSQL_DB}.tbl_product(product_id, name, category, sub_category)\n",
    "            VALUES(:product_id, :name, :category, :sub_category)\n",
    "            \"\"\"\n",
    "        ), {\n",
    "            \"product_id\": qry_prod_id,\n",
    "            \"name\": i[\"product_name\"],\n",
    "            \"category\": i[\"category\"],\n",
    "            \"sub_category\": i[\"sub_category\"],\n",
    "        })\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "    print(\"Successfully migrated\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError msg : {e}\\n\")\n",
    "    session.rollback()\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.execute(text(f\"DROP TABLE IF EXISTS {MYSQL_DB}.tbl_product_price\"))\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {MYSQL_DB}.tbl_product_price(\n",
    "            product_price_id VARCHAR(15) NOT NULL\n",
    "            , product_id VARCHAR(20) NOT NULL\n",
    "            , capital_price FLOAT NOT NULL\n",
    "            , sales_price FLOAT NOT NULL\n",
    "            , profit FLOAT NOT NULL\n",
    "            , discount FLOAT NOT NULL\n",
    "            , PRIMARY KEY (product_price_id)\n",
    "        )\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    qry = spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "            `product name` product_name\n",
    "            , discount\n",
    "            , sales\n",
    "            , ROUND((sales/(1-discount)) / quantity, 4) sales_price\n",
    "        FROM df_csv_superstore\n",
    "        GROUP BY sales, discount, `product id`, `product name`, ROUND((sales/(1-discount)) / quantity, 4)\n",
    "        \"\"\"\n",
    "    )\n",
    "    qry = np.array(qry.toJSON().map(json.loads).collect())\n",
    "    ls_prod_id = session.execute(text(\n",
    "        f\"\"\"\n",
    "        SELECT product_id, name FROM {MYSQL_DB}.tbl_product\n",
    "        \"\"\"\n",
    "    )).mappings().fetchall()\n",
    "\n",
    "    val = str()\n",
    "    for i in range(len(qry)):\n",
    "        prod_prc_id = f\"PRC-{i+1}\"\n",
    "        prod_id = list(filter(\n",
    "            lambda item: item['name'] == qry[i][\"product_name\"], ls_prod_id\n",
    "        ))[0][\"product_id\"]\n",
    "        discount = float(qry[i]['discount'])\n",
    "        capital_price = 0\n",
    "        sales_price = float(qry[i]['sales_price'])\n",
    "        profit = 0\n",
    "        if i == 0:\n",
    "            val += f\"\"\"(\n",
    "                    '{prod_prc_id}', '{prod_id}', '{discount}','{capital_price}', '{sales_price}', '{profit}'\n",
    "                    )\"\"\"\n",
    "        else:\n",
    "            val += f\"\"\", (\n",
    "                    '{prod_prc_id}', '{prod_id}', '{discount}','{capital_price}', '{sales_price}', '{profit}'\n",
    "                    )\"\"\"\n",
    "\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        INSERT INTO {MYSQL_DB}.tbl_product_price(product_price_id, product_id, discount, capital_price, sales_price, profit)\n",
    "        VALUES {val}\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "    print(\"Successfully migrated\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError msg : {e}\\n\")\n",
    "    session.rollback()\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ship\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated\n"
     ]
    }
   ],
   "source": [
    "TBL_SAL_ORD = \"tbl_sales_order\"\n",
    "FK_SAL_ODR_SHIP = \"fk_sal_ord_ship\"\n",
    "try:\n",
    "    qry = session.execute(text(\n",
    "        f\"\"\"\n",
    "        SELECT TABLE_NAME, INDEX_NAME\n",
    "        FROM INFORMATION_SCHEMA.STATISTICS\n",
    "        WHERE index_schema = '{MYSQL_DB}'\n",
    "        AND TABLE_NAME IN('{TBL_SAL_ORD}')\n",
    "        AND INDEX_NAME IN('{FK_SAL_ODR_SHIP}')\n",
    "        \"\"\"\n",
    "    )).mappings().fetchall()\n",
    "    if len(qry) > 0:\n",
    "        for i in qry:\n",
    "            session.execute(text(\n",
    "                f\"\"\"\n",
    "                ALTER TABLE {MYSQL_DB}.{i[\"TABLE_NAME\"]}\n",
    "                    DROP FOREIGN KEY {i[\"INDEX_NAME\"]}\n",
    "                    , DROP INDEX {i[\"INDEX_NAME\"]}\n",
    "                \"\"\"\n",
    "            ))\n",
    "    qry = session.execute(text(\n",
    "        f\"\"\"\n",
    "        SELECT table_name\n",
    "        FROM INFORMATION_SCHEMA.STATISTICS\n",
    "        WHERE index_schema = '{MYSQL_DB}'\n",
    "        AND table_name IN('tbl_sales_order')\n",
    "        AND index_name IN('fk_ship_id')\n",
    "        \"\"\"\n",
    "    )).mappings().fetchall()\n",
    "    if len(qry) > 0:\n",
    "        for i in qry:\n",
    "            session.execute(text(\n",
    "                f\"\"\"\n",
    "                ALTER TABLE {MYSQL_DB}.{i[\"table_name\"]}\n",
    "                    DROP FOREIGN KEY fk_ship_id\n",
    "                    , DROP INDEX fk_ship_id\n",
    "                \"\"\"\n",
    "            ))\n",
    "    session.execute(text(f\"DROP TABLE IF EXISTS {MYSQL_DB}.tbl_ship\"))\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {MYSQL_DB}.tbl_ship(\n",
    "          ship_id VARCHAR(15) NOT NULL\n",
    "          , mode VARCHAR(45) NOT NULL\n",
    "          , PRIMARY KEY (ship_id)\n",
    "        )\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    qry = spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT `ship mode` AS mode FROM df_csv_superstore\n",
    "        GROUP BY `ship mode` ORDER BY `ship mode`\n",
    "        \"\"\"\n",
    "    )\n",
    "    qry = np.array(qry.toJSON().map(json.loads).collect())\n",
    "\n",
    "    val = str()\n",
    "    for i in range(len(qry)):\n",
    "        mode = str(qry[i]['mode']).replace(\"'\", \"\\'\")\n",
    "        val += f\"('SHIP-{i+1}', '{mode}')\" if i == 0 else f\", ('SHIP-{i+1}', '{mode}')\"\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        INSERT INTO {MYSQL_DB}.tbl_ship(ship_id, mode)\n",
    "        VALUES {val}\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "    print(\"Successfully migrated\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError msg : {e}\\n\")\n",
    "    session.rollback()\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated\n"
     ]
    }
   ],
   "source": [
    "TBL_SAL_ORD_DET = \"tbl_sales_order_detail\"\n",
    "FK_SAL_ORD_DET_SAL_ORD = \"fk_sal_ord_det_sal_ord\"\n",
    "try:\n",
    "    qry = session.execute(text(\n",
    "        f\"\"\"\n",
    "        SELECT TABLE_NAME, INDEX_NAME\n",
    "        FROM INFORMATION_SCHEMA.STATISTICS\n",
    "        WHERE index_schema = '{MYSQL_DB}'\n",
    "        AND TABLE_NAME = '{TBL_SAL_ORD_DET}'\n",
    "        AND INDEX_NAME IN('{FK_SAL_ORD_DET_SAL_ORD}')\n",
    "        \"\"\"\n",
    "    )).mappings().fetchall()\n",
    "    if len(qry) > 0:\n",
    "        for i in qry:\n",
    "            session.execute(text(\n",
    "                f\"\"\"\n",
    "                ALTER TABLE {MYSQL_DB}.{i[\"TABLE_NAME\"]}\n",
    "                    DROP FOREIGN KEY {i[\"INDEX_NAME\"]}\n",
    "                    , DROP INDEX {i[\"INDEX_NAME\"]}\n",
    "                \"\"\"\n",
    "            ))\n",
    "    session.execute(text(f\"DROP TABLE IF EXISTS {MYSQL_DB}.tbl_sales_order\"))\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {MYSQL_DB}.tbl_sales_order(\n",
    "          sales_order_id VARCHAR(20) NOT NULL\n",
    "          , order_date DATE NOT NULL\n",
    "          , ship_date DATE NOT NULL\n",
    "          , ship_id VARCHAR(15) NOT NULL\n",
    "          , customer_id VARCHAR(15) NOT NULL\n",
    "          , grand_total_sales FLOAT NOT NULL\n",
    "          , grand_total_profit FLOAT NOT NULL\n",
    "          , PRIMARY KEY (sales_order_id)\n",
    "        )\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    qry = spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "            `order id` sales_order_id\n",
    "            , `ship mode` ship_mode\n",
    "            , to_date(`order date`, 'MM/dd/yyyy') order_date\n",
    "            , to_date(`ship date`, 'MM/dd/yyyy') ship_date\n",
    "            , `customer id` customer_id\n",
    "            , ROUND(SUM(CAST(sales AS FLOAT)), 4) grand_total_sales\n",
    "            , ROUND(SUM(CAST(profit AS FLOAT)), 4) grand_total_profit\n",
    "        FROM df_csv_superstore\n",
    "        GROUP BY `order id`, `order date`, `ship date`, `customer id`, `ship mode`\n",
    "        \"\"\"\n",
    "    )\n",
    "    qry = np.array(qry.toJSON().map(json.loads).collect())\n",
    "\n",
    "    ls_ship_id = session.execute(text(\n",
    "        f\"SELECT ship_id, mode FROM {MYSQL_DB}.tbl_ship\"\n",
    "    )).mappings().fetchall()\n",
    "\n",
    "    val = str()\n",
    "    for i in range(len(qry)):\n",
    "        sales_order_id = str(qry[i]['sales_order_id']).replace(\"'\", \"\\'\")\n",
    "        order_date = str(qry[i]['order_date']).replace(\"'\", \"\\'\")\n",
    "        ship_id = list(filter(\n",
    "            lambda item: item['mode'] == qry[i][\"ship_mode\"], ls_ship_id\n",
    "        ))[0][\"ship_id\"]\n",
    "        ship_date = str(qry[i]['ship_date']).replace(\"'\", \"\\'\")\n",
    "        customer_id = str(qry[i]['customer_id']).replace(\"'\", \"\\'\")\n",
    "        grand_total_sales = float(qry[i]['grand_total_sales'])\n",
    "        grand_total_profit = float(qry[i]['grand_total_profit'])\n",
    "        if i == 0:\n",
    "            val += f\"\"\"(\n",
    "                '{sales_order_id}', '{order_date}', '{ship_id}', '{ship_date}', '{customer_id}', '{grand_total_sales}', '{grand_total_profit}'\n",
    "                )\"\"\"\n",
    "        else:\n",
    "            val += f\"\"\", (\n",
    "                '{sales_order_id}', '{order_date}', '{ship_id}', '{ship_date}', '{customer_id}', '{grand_total_sales}', '{grand_total_profit}'\n",
    "                )\"\"\"\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        INSERT INTO {MYSQL_DB}.tbl_sales_order(sales_order_id, order_date, ship_id, ship_date, customer_id, grand_total_sales, grand_total_profit)\n",
    "        VALUES {val}\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "    print(\"Successfully migrated\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError msg : {e}\\n\")\n",
    "    session.rollback()\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Order Detail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully migrated\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.execute(text(\n",
    "        f\"DROP TABLE IF EXISTS {MYSQL_DB}.tbl_sales_order_detail\"\n",
    "    ))\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {MYSQL_DB}.tbl_sales_order_detail(\n",
    "          sales_order_id VARCHAR(20) NOT NULL\n",
    "          , product_id VARCHAR(15) NOT NULL\n",
    "          , quantity INT NOT NULL\n",
    "          , discount FLOAT NOT NULL\n",
    "          , total_sales FLOAT NOT NULL\n",
    "          , total_profit FLOAT NOT NULL\n",
    "        )\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    qry = spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "            `order id` sales_order_id\n",
    "            , `product id` product_id\n",
    "            , quantity\n",
    "            , discount\n",
    "            , sales total_sales\n",
    "            , profit total_profit\n",
    "        FROM df_csv_superstore\n",
    "        \"\"\"\n",
    "    )\n",
    "    qry = np.array(qry.toJSON().map(json.loads).collect())\n",
    "\n",
    "    val = str()\n",
    "    for i in range(len(qry)):\n",
    "        sales_order_id = str(qry[i]['sales_order_id']).replace(\"'\", \"\\'\")\n",
    "        product_id = str(qry[i]['product_id']).replace(\"'\", \"\\'\")\n",
    "        quantity = int(qry[i]['quantity'])\n",
    "        discount = float(qry[i]['discount'])\n",
    "        total_sales = float(qry[i]['total_sales'])\n",
    "        total_profit = float(qry[i]['total_profit'])\n",
    "        if i == 0:\n",
    "            val += f\"\"\"(\n",
    "                '{sales_order_id}', '{product_id}', '{quantity}', '{discount}', '{total_sales}', '{total_profit}'\n",
    "                )\"\"\"\n",
    "        else:\n",
    "            val += f\"\"\", (\n",
    "                '{sales_order_id}', '{product_id}', '{quantity}', '{discount}', '{total_sales}', '{total_profit}'\n",
    "                )\"\"\"\n",
    "\n",
    "    session.execute(text(\n",
    "        f\"\"\"\n",
    "        INSERT INTO {MYSQL_DB}.tbl_sales_order_detail(sales_order_id, product_id, quantity, discount, total_sales, total_profit)\n",
    "        VALUES {val}\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "    print(\"Successfully migrated\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError msg : {e}\\n\")\n",
    "    session.rollback()\n",
    "    session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
